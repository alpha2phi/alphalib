{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s(): %(message)s\", level=logging.DEBUG\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "> Generic data ingestion routines to ingest data from files to databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def auto_str(cls):\n",
    "    \"\"\"Auto generate string representation of the object.\n",
    "    Args:\n",
    "        cls: Class for which to generate the __str__ method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"%s(%s)\" % (\n",
    "            type(self).__name__,\n",
    "            \", \".join(\"%s=%s\" % item for item in vars(self).items()),\n",
    "        )\n",
    "\n",
    "    cls.__str__ = __str__\n",
    "    return cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ObjectFactory:\n",
    "    \"\"\"Generic object factory.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._builders = {}\n",
    "\n",
    "    def register_builder(self, key, builder):\n",
    "        self._builders[key] = builder\n",
    "\n",
    "    def create(self, key, **kwargs):\n",
    "        builder = self._builders.get(key)\n",
    "        if not builder:\n",
    "            raise ValueError(key)\n",
    "        return builder(**kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DbSinkProvider(ObjectFactory):\n",
    "    \"\"\"Database factory.\"\"\"\n",
    "\n",
    "    def get(self, id, **kwargs):\n",
    "        \"\"\"Create the database interface\"\"\"\n",
    "        return self.create(id, **kwargs)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "class FileSourceProvider(ObjectFactory):\n",
    "    \"\"\"File factory.\"\"\"\n",
    "\n",
    "    def get(self, id, **kwargs):\n",
    "        \"\"\"Create the file interface\"\"\"\n",
    "        return self.create(id, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PgSqlDbBuilder:\n",
    "    \"\"\"PostgreSQL database builder.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._instance = None\n",
    "\n",
    "    def __call__(self, **_ignored):\n",
    "        if not self._instance:\n",
    "            # Load settings from .env\n",
    "            load_dotenv(find_dotenv())\n",
    "            self._instance = PgSqlDb(\n",
    "                os.getenv(\"POSTGRES_HOST\"),\n",
    "                os.getenv(\"POSTGRES_PORT\"),\n",
    "                os.getenv(\"POSTGRES_DB\"),\n",
    "                os.getenv(\"POSTGRES_USER\"),\n",
    "                os.getenv(\"POSTGRES_PASSWORD\"),\n",
    "            )\n",
    "\n",
    "        return self._instance\n",
    "\n",
    "\n",
    "@auto_str\n",
    "class PgSqlDb:\n",
    "    \"\"\"PostgreSQL database.\"\"\"\n",
    "\n",
    "    def __init__(self, host, port, db, user, password):\n",
    "        self._host = host\n",
    "        self._port = port\n",
    "        self._db = db\n",
    "        self._user = user\n",
    "        self._password = password\n",
    "\n",
    "    def get_engine(self):\n",
    "        \"\"\"Create and return sqlalchemy engine.\"\"\"\n",
    "        return create_engine(self.get_conn_str())\n",
    "\n",
    "    def get_conn_str(self):\n",
    "        \"\"\"Return the connection string.\"\"\"\n",
    "        return f\"postgresql+psycopg2://{self._user}:{self._password}@{self._host}:{self._port}/{self._db}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@auto_str\n",
    "class ExcelSource:\n",
    "    \"\"\"Excel file support.\"\"\"\n",
    "\n",
    "    def __init__(self, filepath):\n",
    "        self._filepath = filepath\n",
    "\n",
    "    def read(self):\n",
    "        \"\"\"Read the file and return a `DataFrame`\"\"\"\n",
    "        return pd.read_excel(self._filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Register supported database providers\n",
    "supported_databases = DbSinkProvider()\n",
    "supported_databases.register_builder(\"pgsql\", PgSqlDbBuilder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "# Register supported file types\n",
    "supported_files_types = FileSourceProvider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ingest(excel_file, db_name, table_name, db_type=\"pgsql\", schema=None):\n",
    "    \"\"\"Ingest the file into the database table.\"\"\"\n",
    "    logging.info(\n",
    "        f\"file = {excel_file}, db = {db_name}, table = {table_name}, db type = {db_type}\"\n",
    "    )\n",
    "\n",
    "    # Create database engine\n",
    "    db = db_provider.get(db_type)\n",
    "    engine = db.get_engine()\n",
    "\n",
    "    # Inspect the target table schema\n",
    "    inspector = inspect(engine)\n",
    "    dtypes = {}\n",
    "    for column in inspector.get_columns(table_name, schema=schema):\n",
    "        dtypes[column[\"name\"]] = column[\"type\"]\n",
    "    logging.info(dtypes)\n",
    "\n",
    "    # Load the excel into database\n",
    "    df = pd.read_excel(excel_file)\n",
    "    df.to_sql(\n",
    "        table_name, engine, if_exists=\"append\", chunksize=500, index=False, dtype=dtypes\n",
    "    )\n",
    "\n",
    "    # TODO - Validation\n",
    "    print(f\"\\nTotal records in {excel_file} - {len(df)}\")\n",
    "    for c in df.columns:\n",
    "        print(f\"{c} - {df[c].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_doc(ingest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgsql_db = db_provider.get(\"pgsql\")\n",
    "#pgsql_db.get_conn_str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_data.loader.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
